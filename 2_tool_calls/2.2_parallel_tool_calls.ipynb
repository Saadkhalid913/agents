{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df53fe2a",
   "metadata": {},
   "source": [
    "# 2.2 Parallel Tool Calls\n",
    "\n",
    "When a question requires multiple independent pieces of information, the model can request several tool calls in a single turn. Instead of calling one tool, waiting for the result, calling the next, and so on, it batches all requests together.\n",
    "\n",
    "This is a latency optimization: four 300ms API calls complete in ~300ms (parallel) instead of ~1200ms (sequential). But it's also a capability -- the model has to recognize which parts of the question are independent and can be answered simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43c4b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T03:36:30.619839Z",
     "iopub.status.busy": "2026-02-09T03:36:30.619721Z",
     "iopub.status.idle": "2026-02-09T03:36:31.172957Z",
     "shell.execute_reply": "2026-02-09T03:36:31.171659Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv('OPENROUTER_API_KEY'),\n",
    "    base_url='https://openrouter.ai/api/v1',\n",
    ")\n",
    "\n",
    "MODEL = 'google/gemini-2.5-flash-lite'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34307c4a",
   "metadata": {},
   "source": [
    "## Define multiple tools\n",
    "\n",
    "Three independent tools that the model can call in parallel. Each one returns a different type of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4609ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T03:36:31.176216Z",
     "iopub.status.busy": "2026-02-09T03:36:31.175972Z",
     "iopub.status.idle": "2026-02-09T03:36:31.184514Z",
     "shell.execute_reply": "2026-02-09T03:36:31.183338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 3 tools: ['get_weather', 'get_stock_price', 'get_news_headlines']\n"
     ]
    }
   ],
   "source": [
    "# Three independent tools\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather for a city. Returns temperature and conditions.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City name\"},\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_stock_price\",\n",
    "            \"description\": \"Get the current stock price for a ticker symbol. Returns price in USD.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"ticker\": {\"type\": \"string\", \"description\": \"Stock ticker, e.g. AAPL\"},\n",
    "                },\n",
    "                \"required\": [\"ticker\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_news_headlines\",\n",
    "            \"description\": \"Get the latest news headlines for a topic. Returns a list of headline strings.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\"type\": \"string\", \"description\": \"News topic to search for\"},\n",
    "                },\n",
    "                \"required\": [\"topic\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Simulated implementations\n",
    "def get_weather(city: str) -> dict:\n",
    "    time.sleep(0.3)  # Simulate API latency\n",
    "    data = {\n",
    "        \"San Francisco\": {\"temp_f\": 62, \"conditions\": \"Foggy\"},\n",
    "        \"New York\": {\"temp_f\": 45, \"conditions\": \"Partly cloudy\"},\n",
    "        \"Tokyo\": {\"temp_f\": 71, \"conditions\": \"Clear\"},\n",
    "    }\n",
    "    return data.get(city, {\"temp_f\": 70, \"conditions\": \"Unknown\"})\n",
    "\n",
    "def get_stock_price(ticker: str) -> dict:\n",
    "    time.sleep(0.3)  # Simulate API latency\n",
    "    prices = {\n",
    "        \"AAPL\": {\"price\": 198.50, \"change\": \"+1.2%\"},\n",
    "        \"GOOGL\": {\"price\": 175.30, \"change\": \"-0.5%\"},\n",
    "        \"MSFT\": {\"price\": 425.80, \"change\": \"+0.8%\"},\n",
    "    }\n",
    "    return prices.get(ticker, {\"price\": 0, \"change\": \"N/A\"})\n",
    "\n",
    "def get_news_headlines(topic: str) -> dict:\n",
    "    time.sleep(0.3)  # Simulate API latency\n",
    "    return {\"headlines\": [\n",
    "        f\"Breaking: Major developments in {topic}\",\n",
    "        f\"{topic} sector sees unprecedented growth\",\n",
    "        f\"Experts weigh in on the future of {topic}\",\n",
    "    ]}\n",
    "\n",
    "available_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"get_stock_price\": get_stock_price,\n",
    "    \"get_news_headlines\": get_news_headlines,\n",
    "}\n",
    "\n",
    "print(f'Defined {len(tools)} tools: {[t[\"function\"][\"name\"] for t in tools]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa9bb0",
   "metadata": {},
   "source": [
    "## Handle parallel tool calls\n",
    "\n",
    "When the model returns multiple tool_calls in one response, we execute them concurrently using a thread pool. Each result is linked back to its tool_call via `tool_call_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d56b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T03:36:31.186386Z",
     "iopub.status.busy": "2026-02-09T03:36:31.186285Z",
     "iopub.status.idle": "2026-02-09T03:36:31.197447Z",
     "shell.execute_reply": "2026-02-09T03:36:31.192879Z"
    }
   },
   "outputs": [],
   "source": [
    "def execute_tool_calls_parallel(tool_calls) -> list[dict]:\n",
    "    \"\"\"Execute multiple tool calls concurrently and return results.\"\"\"\n",
    "    def execute_one(tc):\n",
    "        fn = available_functions[tc.function.name]\n",
    "        args = json.loads(tc.function.arguments)\n",
    "        result = fn(**args)\n",
    "        return {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tc.id,\n",
    "            \"content\": json.dumps(result),\n",
    "        }\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=len(tool_calls)) as executor:\n",
    "        results = list(executor.map(execute_one, tool_calls))\n",
    "    return results\n",
    "\n",
    "\n",
    "def execute_tool_calls_sequential(tool_calls) -> list[dict]:\n",
    "    \"\"\"Execute tool calls one at a time (for comparison).\"\"\"\n",
    "    results = []\n",
    "    for tc in tool_calls:\n",
    "        fn = available_functions[tc.function.name]\n",
    "        args = json.loads(tc.function.arguments)\n",
    "        result = fn(**args)\n",
    "        results.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tc.id,\n",
    "            \"content\": json.dumps(result),\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_with_tools(user_message: str, parallel: bool = True) -> str:\n",
    "    \"\"\"Complete tool-calling lifecycle with support for parallel calls.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL, messages=messages, tools=tools,\n",
    "    )\n",
    "\n",
    "    assistant_msg = response.choices[0].message\n",
    "\n",
    "    if not assistant_msg.tool_calls:\n",
    "        return assistant_msg.content\n",
    "\n",
    "    # Show what the model requested\n",
    "    print(f'Model requested {len(assistant_msg.tool_calls)} tool call(s):')\n",
    "    for tc in assistant_msg.tool_calls:\n",
    "        print(f'  - {tc.function.name}({tc.function.arguments})')\n",
    "    print()\n",
    "\n",
    "    # Execute all tool calls\n",
    "    start = time.time()\n",
    "    if parallel:\n",
    "        tool_results = execute_tool_calls_parallel(assistant_msg.tool_calls)\n",
    "    else:\n",
    "        tool_results = execute_tool_calls_sequential(assistant_msg.tool_calls)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    mode = 'parallel' if parallel else 'sequential'\n",
    "    print(f'Executed {len(tool_results)} tools ({mode}): {elapsed:.3f}s')\n",
    "    for tr in tool_results:\n",
    "        print(f'  Result: {tr[\"content\"]}')\n",
    "    print()\n",
    "\n",
    "    # Send all results back\n",
    "    messages.append(assistant_msg)\n",
    "    messages.extend(tool_results)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL, messages=messages, tools=tools,\n",
    "    )\n",
    "\n",
    "    final = response.choices[0].message.content\n",
    "    print(f'Final answer: {final}')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ec285",
   "metadata": {},
   "source": [
    "## Run it: parallel vs sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00d3b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T03:36:31.251493Z",
     "iopub.status.busy": "2026-02-09T03:36:31.251060Z",
     "iopub.status.idle": "2026-02-09T03:36:38.288945Z",
     "shell.execute_reply": "2026-02-09T03:36:38.288104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PARALLEL EXECUTION ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model requested 3 tool call(s):\n",
      "  - get_weather({\"city\":\"Tokyo\"})\n",
      "  - get_stock_price({\"ticker\":\"AAPL\"})\n",
      "  - get_news_headlines({\"topic\":\"AI\"})\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed 3 tools (parallel): 0.311s\n",
      "  Result: {\"temp_f\": 71, \"conditions\": \"Clear\"}\n",
      "  Result: {\"price\": 198.5, \"change\": \"+1.2%\"}\n",
      "  Result: {\"headlines\": [\"Breaking: Major developments in AI\", \"AI sector sees unprecedented growth\", \"Experts weigh in on the future of AI\"]}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: The weather in Tokyo is clear and 71°F. Apple's stock price is $198.5, up 1.2%. Here are the latest news headlines about AI: Breaking: Major developments in AI, AI sector sees unprecedented growth, Experts weigh in on the future of AI.\n",
      "\n",
      "=== SEQUENTIAL EXECUTION ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model requested 3 tool call(s):\n",
      "  - get_weather({\"city\":\"Tokyo\"})\n",
      "  - get_stock_price({\"ticker\":\"AAPL\"})\n",
      "  - get_news_headlines({\"topic\":\"AI\"})\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed 3 tools (sequential): 0.909s\n",
      "  Result: {\"temp_f\": 71, \"conditions\": \"Clear\"}\n",
      "  Result: {\"price\": 198.5, \"change\": \"+1.2%\"}\n",
      "  Result: {\"headlines\": [\"Breaking: Major developments in AI\", \"AI sector sees unprecedented growth\", \"Experts weigh in on the future of AI\"]}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: The weather in Tokyo is clear and 71°F. AAPL's stock price is $198.5, up 1.2%. The latest news headlines about AI are: \"Breaking: Major developments in AI\", \"AI sector sees unprecedented growth\", and \"Experts weigh in on the future of AI\".\n",
      "\n",
      "Both produce the same answer, but parallel is faster when tools have latency.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question that requires multiple tools\n",
    "query = \"What's the weather in Tokyo, what's AAPL's stock price, and what's the latest news about AI?\"\n",
    "\n",
    "print('=== PARALLEL EXECUTION ===')\n",
    "print()\n",
    "answer_par = run_with_tools(query, parallel=True)\n",
    "\n",
    "print()\n",
    "print('=== SEQUENTIAL EXECUTION ===')\n",
    "print()\n",
    "answer_seq = run_with_tools(query, parallel=False)\n",
    "\n",
    "print()\n",
    "print('Both produce the same answer, but parallel is faster when tools have latency.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0631d21d",
   "metadata": {},
   "source": [
    "## Timing comparison\n",
    "\n",
    "Each simulated tool takes 300ms. With 3 parallel calls, execution should take ~300ms total instead of ~900ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2336fc14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T03:36:38.290986Z",
     "iopub.status.busy": "2026-02-09T03:36:38.290853Z",
     "iopub.status.idle": "2026-02-09T03:36:39.531134Z",
     "shell.execute_reply": "2026-02-09T03:36:39.530406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 tools (each 300ms):\n",
      "  Parallel:   0.305s\n",
      "  Sequential: 0.916s\n",
      "  Speedup:    3.0x\n"
     ]
    }
   ],
   "source": [
    "# Precise timing comparison\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "# Create fake tool_calls for timing only\n",
    "class FakeTC:\n",
    "    def __init__(self, name, args):\n",
    "        self.id = f'call_{name}'\n",
    "        self.function = MagicMock()\n",
    "        self.function.name = name\n",
    "        self.function.arguments = json.dumps(args)\n",
    "\n",
    "fake_calls = [\n",
    "    FakeTC('get_weather', {'city': 'Tokyo'}),\n",
    "    FakeTC('get_stock_price', {'ticker': 'AAPL'}),\n",
    "    FakeTC('get_news_headlines', {'topic': 'AI'}),\n",
    "]\n",
    "\n",
    "# Time parallel\n",
    "start = time.time()\n",
    "execute_tool_calls_parallel(fake_calls)\n",
    "parallel_time = time.time() - start\n",
    "\n",
    "# Time sequential\n",
    "start = time.time()\n",
    "execute_tool_calls_sequential(fake_calls)\n",
    "sequential_time = time.time() - start\n",
    "\n",
    "print(f'3 tools (each 300ms):')\n",
    "print(f'  Parallel:   {parallel_time:.3f}s')\n",
    "print(f'  Sequential: {sequential_time:.3f}s')\n",
    "print(f'  Speedup:    {sequential_time / parallel_time:.1f}x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
